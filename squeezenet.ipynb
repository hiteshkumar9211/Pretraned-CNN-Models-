{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525e2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec5156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader for Tonji\n",
    "class PalmROIDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_list = sorted([f for f in os.listdir(root_dir) if f.endswith(\".bmp\")])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image[..., np.newaxis]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # Extract person ID (e.g., '00001.bmp' to '00020.bmp' -> person 1)\n",
    "        try:\n",
    "            img_number = int(img_name.split(\".\")[0])\n",
    "            person_id = ((img_number - 1) // 20) + 1\n",
    "            label = person_id - 1\n",
    "            if not (0 <= label <= 299):\n",
    "                raise ValueError(f\"Label {label + 1} out of range (1 to 300) for {img_name}\")\n",
    "        except (ValueError, IndexError):\n",
    "            raise ValueError(f\"Invalid filename format for label: {img_name}\")\n",
    "        return image, label, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8084465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SqueezeNet with VGG-16 style modification\n",
    "class SqueezeNetFeature(nn.Module):\n",
    "    def __init__(self, num_classes=300):\n",
    "        super(SqueezeNetFeature, self).__init__()\n",
    "        # Load pretrained SqueezeNet\n",
    "        self.model = models.squeezenet1_1(weights='IMAGENET1K_V1')\n",
    "        # Modify first convolutional layer for 1-channel input\n",
    "        self.model.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1)\n",
    "        # Copy pretrained weights for conv1 (average RGB channels)\n",
    "        with torch.no_grad():\n",
    "            self.model.features[0].weight.copy_(self.model.features[0].weight.mean(dim=1, keepdim=True))\n",
    "            self.model.features[0].bias.copy_(self.model.features[0].bias)\n",
    "        # Modify classifier to match VGG-16 style\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))  # Adjust pooling to match VGG-16 output size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 4096),  # Flatten and match VGG-16 feature size\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        # Initialize new classifier layers\n",
    "        for m in self.classifier:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        x = self.model.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if return_features:\n",
    "            x = self.classifier[:4](x)  \n",
    "            return x\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f987decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune SqueezeNet on Tonji\n",
    "def fine_tune_squeezenet(model, train_loader, device, epochs=50):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Differential learning rates\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.model.features[0].parameters(), 'lr': 0.001},\n",
    "        {'params': model.model.features[1:].parameters(), 'lr': 0.0001},\n",
    "        {'params': model.classifier.parameters(), 'lr': 0.001},\n",
    "    ], lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "    model.train()\n",
    "    prev_lr = [group['lr'] for group in optimizer.param_groups]\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, y, _ in tqdm(train_loader, desc=f\"Fine-Tuning Epoch {epoch+1}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Fine-Tuning Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        scheduler.step(avg_loss)\n",
    "        current_lr = [group['lr'] for group in optimizer.param_groups]\n",
    "        if any(lr != prev_lr[i] for i, lr in enumerate(current_lr)):\n",
    "            print(f\"Epoch {epoch+1}: Learning rates updated to {current_lr}\")\n",
    "        prev_lr = current_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69f0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from a dataloader\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    img_names = []\n",
    "    with torch.no_grad():\n",
    "        for x, y, names in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            x = x.to(device)\n",
    "            f = model(x, return_features=True).cpu().numpy()\n",
    "            features_list.append(f)\n",
    "            labels_list.extend(y.numpy())\n",
    "            img_names.extend(names)\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.array(labels_list)\n",
    "    return features, labels, img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49cd018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics (Top-1, Top-5, ROC AUC, EER, FAR, FRR)\n",
    "def compute_metrics(features, labels, clf):\n",
    "    decision_scores = clf.decision_function(features)\n",
    "    topk_acc = {}\n",
    "    for k in [1, 5]:\n",
    "        top_k_indices = np.argsort(decision_scores, axis=1)[:, -k:]\n",
    "        correct = 0\n",
    "        for i, top_k in enumerate(top_k_indices):\n",
    "            if labels[i] in top_k:\n",
    "                correct += 1\n",
    "        topk_acc[k] = correct / len(labels)\n",
    "    y_true, y_score = [], []\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(i + 1, len(labels)):\n",
    "            score_i = decision_scores[i, labels[i]]\n",
    "            score_j = decision_scores[j, labels[j]]\n",
    "            sim = score_i + score_j\n",
    "            y_score.append(sim)\n",
    "            y_true.append(1 if labels[i] == labels[j] else 0)\n",
    "    if len(set(y_true)) <= 1:\n",
    "        print(\"Warning: y_true contains only one class. Setting ROC AUC, EER, FAR, FRR to 0.1.\")\n",
    "        roc_auc = 0.1\n",
    "        eer = 0.1\n",
    "        far = 0.1\n",
    "        frr = 0.1\n",
    "    else:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fnr = 1 - tpr\n",
    "        diff = np.abs(fnr - fpr)\n",
    "        if np.all(np.isnan(diff)):\n",
    "            print(\"Warning: All-NaN slice in EER calculation. Setting EER, FAR, FRR to 0.1.\")\n",
    "            eer = 0.1\n",
    "            far = 0.1\n",
    "            frr = 0.1\n",
    "        else:\n",
    "            eer_idx = np.nanargmin(diff)\n",
    "            eer = (fpr[eer_idx] + fnr[eer_idx]) / 2\n",
    "            far = fpr[eer_idx]\n",
    "            frr = fnr[eer_idx]\n",
    "    return topk_acc, roc_auc, eer, far, frr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940c7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code\n",
    "session1_root = r\"C:\\Users\\hiteshk\\Desktop\\Deep Learning Approaches for roi extraction and using same for palm print recognisation\\Tonji\\ROI\\session1\"\n",
    "session2_root = r\"C:\\Users\\hiteshk\\Desktop\\Deep Learning Approaches for roi extraction and using same for palm print recognisation\\Tonji\\ROI\\session2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8401a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b53eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for Tonji\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ca636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tongji datasets\n",
    "dataset1 = PalmROIDataset(session1_root, transform=transform)\n",
    "dataset2 = PalmROIDataset(session2_root, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ce61cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 images: 6000\n",
      "Session 2 images: 6000\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset sizes\n",
    "print(f\"Session 1 images: {len(dataset1)}\")\n",
    "print(f\"Session 2 images: {len(dataset2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2a8546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 12000\n"
     ]
    }
   ],
   "source": [
    "# Combine datasets\n",
    "full_dataset = ConcatDataset([dataset1, dataset2])\n",
    "print(f\"Total images: {len(full_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a6efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test (80/20)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31d4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1917838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1: 100%|██████████| 300/300 [00:45<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 1, Loss: 5.8606, Accuracy: 0.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 2: 100%|██████████| 300/300 [00:44<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 2, Loss: 5.4996, Accuracy: 0.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 3: 100%|██████████| 300/300 [00:39<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 3, Loss: 5.4176, Accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 4: 100%|██████████| 300/300 [00:38<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 4, Loss: 5.3732, Accuracy: 0.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 5: 100%|██████████| 300/300 [00:38<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 5, Loss: 5.3167, Accuracy: 1.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 6: 100%|██████████| 300/300 [00:38<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 6, Loss: 5.2340, Accuracy: 1.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 7: 100%|██████████| 300/300 [00:38<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 7, Loss: 5.1148, Accuracy: 2.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 8: 100%|██████████| 300/300 [00:39<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 8, Loss: 4.9535, Accuracy: 3.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 9: 100%|██████████| 300/300 [00:38<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 9, Loss: 4.7958, Accuracy: 4.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 10: 100%|██████████| 300/300 [00:39<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 10, Loss: 4.6153, Accuracy: 5.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 11: 100%|██████████| 300/300 [00:38<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 11, Loss: 4.3270, Accuracy: 8.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 12: 100%|██████████| 300/300 [00:38<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 12, Loss: 3.9445, Accuracy: 12.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 13: 100%|██████████| 300/300 [00:37<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 13, Loss: 3.4657, Accuracy: 20.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 14: 100%|██████████| 300/300 [00:38<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 14, Loss: 3.0028, Accuracy: 27.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 15: 100%|██████████| 300/300 [00:37<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 15, Loss: 2.5674, Accuracy: 36.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 16: 100%|██████████| 300/300 [00:37<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 16, Loss: 2.1701, Accuracy: 44.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 17: 100%|██████████| 300/300 [00:37<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 17, Loss: 1.7778, Accuracy: 53.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 18: 100%|██████████| 300/300 [00:38<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 18, Loss: 1.5240, Accuracy: 58.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 19: 100%|██████████| 300/300 [00:38<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 19, Loss: 1.3297, Accuracy: 64.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 20: 100%|██████████| 300/300 [00:37<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 20, Loss: 1.1106, Accuracy: 69.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 21: 100%|██████████| 300/300 [00:37<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 21, Loss: 0.9799, Accuracy: 72.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 22: 100%|██████████| 300/300 [00:37<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 22, Loss: 0.8545, Accuracy: 76.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 23: 100%|██████████| 300/300 [00:37<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 23, Loss: 0.7372, Accuracy: 78.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 24: 100%|██████████| 300/300 [00:37<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 24, Loss: 0.6653, Accuracy: 80.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 25: 100%|██████████| 300/300 [00:39<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 25, Loss: 0.6239, Accuracy: 81.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 26: 100%|██████████| 300/300 [00:39<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 26, Loss: 0.5673, Accuracy: 83.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 27: 100%|██████████| 300/300 [00:38<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 27, Loss: 0.5227, Accuracy: 84.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 28: 100%|██████████| 300/300 [00:38<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 28, Loss: 0.4747, Accuracy: 86.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 29: 100%|██████████| 300/300 [00:38<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 29, Loss: 0.4727, Accuracy: 86.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 30: 100%|██████████| 300/300 [00:38<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 30, Loss: 0.4058, Accuracy: 88.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 31: 100%|██████████| 300/300 [00:38<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 31, Loss: 0.4222, Accuracy: 87.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 32: 100%|██████████| 300/300 [00:38<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 32, Loss: 0.3916, Accuracy: 88.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 33: 100%|██████████| 300/300 [00:38<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 33, Loss: 0.3923, Accuracy: 88.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 34: 100%|██████████| 300/300 [00:38<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 34, Loss: 0.3515, Accuracy: 89.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 35: 100%|██████████| 300/300 [00:38<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 35, Loss: 0.3191, Accuracy: 90.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 36: 100%|██████████| 300/300 [00:38<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 36, Loss: 0.3279, Accuracy: 90.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 37: 100%|██████████| 300/300 [00:38<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 37, Loss: 0.3011, Accuracy: 90.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 38: 100%|██████████| 300/300 [00:38<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 38, Loss: 0.2809, Accuracy: 91.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 39: 100%|██████████| 300/300 [00:38<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 39, Loss: 0.2969, Accuracy: 91.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 40: 100%|██████████| 300/300 [00:38<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 40, Loss: 0.2619, Accuracy: 92.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 41: 100%|██████████| 300/300 [00:38<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 41, Loss: 0.2428, Accuracy: 92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 42: 100%|██████████| 300/300 [00:39<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 42, Loss: 0.2567, Accuracy: 92.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 43: 100%|██████████| 300/300 [00:38<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 43, Loss: 0.2531, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 44: 100%|██████████| 300/300 [00:38<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 44, Loss: 0.2315, Accuracy: 93.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 45: 100%|██████████| 300/300 [00:38<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 45, Loss: 0.2325, Accuracy: 93.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 46: 100%|██████████| 300/300 [00:38<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 46, Loss: 0.2366, Accuracy: 93.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 47: 100%|██████████| 300/300 [00:38<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 47, Loss: 0.2217, Accuracy: 93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 48: 100%|██████████| 300/300 [00:38<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 48, Loss: 0.2162, Accuracy: 93.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 49: 100%|██████████| 300/300 [00:38<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 49, Loss: 0.2241, Accuracy: 93.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 50: 100%|██████████| 300/300 [00:38<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning Epoch 50, Loss: 0.2130, Accuracy: 93.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fine-tune SqueezeNet\n",
    "model = SqueezeNetFeature().to(device)\n",
    "fine_tune_squeezenet(model, train_loader, device, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a784827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 300/300 [00:32<00:00,  9.37it/s]\n",
      "Extracting features: 100%|██████████| 75/75 [00:10<00:00,  7.15it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract features\n",
    "train_features, train_labels, _ = extract_features(model, train_loader, device)\n",
    "test_features, test_labels, _ = extract_features(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74c650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 300\n"
     ]
    }
   ],
   "source": [
    "# Verify number of classes\n",
    "num_classes = len(np.unique(np.concatenate((train_labels, test_labels))))\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "if num_classes != 300:\n",
    "    raise ValueError(f\"Expected 300 classes, but found {num_classes}. Verify filename format (e.g., '00001.bmp' to '12000.bmp').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4114bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "train_features = train_features / np.linalg.norm(train_features, axis=1, keepdims=True)\n",
    "test_features = test_features / np.linalg.norm(test_features, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c08368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with RBF kernel and hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7799b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM parameters: {'C': 10, 'gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf', decision_function_shape='ovr', probability=False)\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "print(f\"Best SVM parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "295a19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best estimator\n",
    "svm_clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0486a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "topk_acc, roc_auc, eer, far, frr = compute_metrics(test_features, test_labels, svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b21318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Identification Accuracy: 96.67%\n",
      "Top-5 Identification Accuracy: 99.25%\n",
      "ROC AUC: 0.4969\n",
      "EER: 0.5031\n",
      "FAR: 0.5031\n",
      "FRR: 0.5031\n"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "print(f\"Top-1 Identification Accuracy: {topk_acc[1]*100:.2f}%\")\n",
    "print(f\"Top-5 Identification Accuracy: {topk_acc[5]*100:.2f}%\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"EER: {eer:.4f}\")\n",
    "print(f\"FAR: {far:.4f}\")\n",
    "print(f\"FRR: {frr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
